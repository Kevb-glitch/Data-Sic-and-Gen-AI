#Data Preparation and Machine Learning Workflow

##Overview

This notebook explores a basic machine learning workflow, focusing on data loading, preprocessing, and model training. The aim is to demonstrate how data preparation decisions influence model performance, particularly in applied business and consulting contexts.

Rather than optimising model performance, the emphasis is on understanding the practical steps involved in preparing data and training a model, as well as reflecting on how these steps would scale in real organisational settings.


import pandas as pd
import numpy as np

from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

## Dataset

For this demonstration, a built-in dataset from scikit-learn is used. While this dataset is relatively clean compared to real-world business data, it provides a useful example for illustrating the core stages of a machine learning workflow.

# Load the dataset
data = load_diabetes(as_frame=True)

# Convert to DataFrame
df = data.frame

# Display the first few rows
df.head()

## Initial Data Inspection

Before training any model, it is important to inspect the dataset to understand its structure, features, and potential data quality issues.

# Check dataset information
df.info()

# Check for missing values
df.isnull().sum()

## Data Quality Considerations

In this case, the dataset does not contain missing values, which simplifies preprocessing. However, real organisational datasets often contain incomplete, inconsistent, or noisy data, making this stage significantly more complex and time-consuming.

# Separate features and target variable
X = df.drop(columns=['target'])
y = df['target']

## Train-Test Split

To evaluate model performance fairly, the dataset is split into training and testing sets. This helps assess how well the model generalises to unseen data.

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


## Model Selection

A linear regression model is used for this demonstration. While simple, linear regression provides a clear and interpretable baseline, making it suitable for illustrating fundamental machine learning concepts without unnecessary complexity.


# Initialise the model
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)

## Model Prediction and Evaluation

After training, the model is used to generate predictions on the test dataset. Model performance is evaluated using mean squared error (MSE), a commonly used regression metric.

# Generate predictions
y_pred = model.predict(X_test)

# Calculate mean squared error
mse = mean_squared_error(y_test, y_pred)

mse

## Reflection

This notebook demonstrates how a basic machine learning workflow depends heavily on data preparation and evaluation decisions. Even with a simple model and a clean dataset, meaningful effort is required to structure the data correctly and assess model performance.

In real business and consulting contexts, datasets are often far messier, with missing values, inconsistent formats, and changing distributions over time. These challenges can significantly impact model reliability and highlight why data preparation and validation are often more critical than model complexity itself.


